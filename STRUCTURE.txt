PROJECT STRUCTURE - VideoAgent (Standardized)
===============================================

VideoAgent_Main/
â”œâ”€â”€ ğŸ“„ config.py                   # Centralized configuration management
â”œâ”€â”€ ğŸ“„ video_agent.py              # Main VideoAgent orchestrator class
â”œâ”€â”€ ğŸ“„ main.py                     # CLI entry point with argument parsing
â”œâ”€â”€ ğŸ“„ parse_data.py               # Data processing and validation utilities
â”œâ”€â”€ ğŸ“„ test_import.py              # Import validation test script
â”œâ”€â”€ ğŸ“„ __init__.py                 # Package initialization
â”‚
â”œâ”€â”€ ğŸ“ core/                       # Core data structures and state management
â”‚   â”œâ”€â”€ video_memory.py            # VideoMemory class for frame and analysis state
â”‚   â””â”€â”€ __init__.py                # Core module exports
â”‚
â”œâ”€â”€ ğŸ“ processors/                 # Specialized processing modules
â”‚   â”œâ”€â”€ caption_processor.py       # CaptionProcessor for frame analysis
â”‚   â”œâ”€â”€ question_processor.py      # QuestionProcessor for Q&A and evaluation
â”‚   â””â”€â”€ __init__.py                # Processor module exports
â”‚
â”œâ”€â”€ ğŸ“ utils/                      # Utility modules and helpers
â”‚   â”œâ”€â”€ AIML_API.py               # AIMLClient for LLM API interactions
â”‚   â”œâ”€â”€ utils_clip.py             # CLIPEmbeddingManager for frame retrieval
â”‚   â”œâ”€â”€ general.py          # CacheManager and general utilities
â”‚   â””â”€â”€ __init__.py               # Utility module exports
â”‚
â”œâ”€â”€ ğŸ“ dataset/                    # Input data directory
â”‚   â”œâ”€â”€ subset_anno.json          # Video annotations and questions
â”‚   â”œâ”€â”€ lavila_subset.json        # Pre-computed LaViLa captions
â”‚   â”œâ”€â”€ test_one_video.txt        # Test video list
â”‚   â””â”€â”€ videos/                   # Video files (not in repository)
â”‚
â”œâ”€â”€ ğŸ“ cache/                      # Performance optimization cache
â”‚   â”œâ”€â”€ cache_llm.pkl             # LLM response cache
â”‚   â””â”€â”€ cache_clip.pkl            # CLIP embedding cache
â”‚
â”œâ”€â”€ ğŸ“ output/                     # Experiment results directory
â”‚   â””â”€â”€ [experiment_name]/        # Per-experiment outputs
â”‚       â”œâ”€â”€ result.json           # Aggregated experiment results
â”‚       â”œâ”€â”€ accuracy.txt          # Performance metrics and statistics
â”‚       â”œâ”€â”€ logging.log           # Main experiment logs
â”‚       â”œâ”€â”€ llm.log              # LLM interaction logs (optional)
â”‚       â””â”€â”€ videos/               # Individual video analysis results
â”‚           â””â”€â”€ [video_id]/       # Per-video outputs
â”‚               â”œâ”€â”€ frames/       # Sampled frames as PNG files
â”‚               â”œâ”€â”€ memory.txt    # Complete video memory state
â”‚               â”œâ”€â”€ question.txt  # Formatted question with options
â”‚               â”œâ”€â”€ result.json   # Video-specific results
â”‚               â””â”€â”€ logging.log   # Video processing logs
â”‚
â””â”€â”€ ğŸ“ __pycache__/               # Python bytecode cache (auto-generated)


CORE COMPONENTS (Standardized Architecture)
==========================================

1. config.py - Centralized Configuration Management
---------------------------------------------------
   Purpose: Single source of truth for all configuration parameters
   
   Configuration Categories:
   - Model Settings:        DEFAULT_SCHEDULER_MODEL, DEFAULT_VIEWER_MODEL
   - Processing Parameters: MAX_ROUNDS, MAX_RETRIEVED_FRAMES, DEFAULT_INITIAL_FRAMES
   - API Configuration:     AIML_API_KEY, AIML_BASE_URL, LLM_TEMPERATURE
   - File Paths:           VIDEO_DIR, ANNOTATION_FILE, CACHE_DIR, OUTPUT_DIR
   - Caching Options:      USE_CACHE, CACHE_LLM_FILE, CACHE_CLIP_FILE
   - Logging Settings:     LOG_LEVEL
   - Processing Options:   DEFAULT_MAX_PROCESSES, INPUT_FRAME_INTERVAL

2. video_agent.py - Main Orchestrator Class
--------------------------------------------
   VideoAgent Class:
   - Coordinates entire video analysis pipeline
   - Manages experiment lifecycle and configuration
   - Handles multi-processing and result aggregation
   
   Key Methods:
   - run_experiment()              : Execute complete experiment with configuration
   - process_single_video()        : Process individual video through full pipeline
   - _run_analysis_pipeline()      : Iterative analysis with confidence evaluation
   - _create_output_directory()    : Generate structured output directories
   - _setup_logging()             : Configure experiment and LLM logging
   - _process_videos()            : Coordinate video processing (single/multi-process)

3. core/video_memory.py - Video State Management
-----------------------------------------------
   VideoMemory Class:
   - Encapsulates video frames and analysis state
   - Manages sampled frame indices and captions
   - Maintains overview and event descriptions
   
   Key Methods:
   - add_sampled_frames()         : Add new frame indices to memory
   - update_caption()             : Store frame caption
   - update_event()               : Store frame event description
   - update_overview()            : Update overall video understanding
   - output()                     : Export memory state and frames to disk
   - __str__()                    : Format memory content for display

4. processors/caption_processor.py - Caption Generation
-------------------------------------------------------
   CaptionProcessor Class:
   - Handles frame caption generation and multi-level analysis
   - Supports both detailed and multi-level caption functions
   - Manages LaViLa pre-computed caption loading
   
   Key Methods:
   - generate_detailed_captions()    : Create visual descriptions for frames
   - generate_multi_level_captions() : Combined visual + event understanding
   - load_lavila_captions()          : Load pre-computed captions from file
   - _parse_and_store_captions()     : Parse LLM responses and update memory
   - _generate_event_descriptions()  : High-level event analysis

5. processors/question_processor.py - Q&A and Evaluation
--------------------------------------------------------
   QuestionProcessor Class:
   - Manages question answering and confidence evaluation
   - Handles intelligent frame resampling based on analysis
   - Evaluates answer trustworthiness and completeness
   
   Key Methods:
   - answer_question()               : Generate answer from video analysis
   - evaluate_confidence()           : Assess answer confidence (1-3 scale)
   - generate_segment_steps()        : Smart frame resampling strategy
   - _process_segment_response()     : Parse segment selection and frame counts

6. utils/AIML_API.py - LLM API Interface
----------------------------------------
   AIMLClient Class:
   - Unified interface for text and image-based LLM interactions
   - Handles multiple input types (paths, numpy arrays, bytes)
   - Manages API configuration and error handling
   
   Key Methods:
   - get_text_response()             : Text-only LLM requests
   - get_image_response()            : Vision-language model requests
   - _image_to_base64()             : Image format conversion
   
   Legacy Functions (for backward compatibility):
   - get_text_response(), get_image_response(), image_to_bytes_str()

7. utils/general.py - General Utilities
---------------------------------------------
   CacheManager Class:
   - Manages persistent LLM response caching with SHA256 hashing
   - Handles cache file corruption and initialization
   
   Utility Functions:
   - get_llm_response()              : Unified LLM interface with caching
   - get_video_frames()              : Video frame extraction with OpenCV
   - parse_analysis_and_json()       : Parse LLM responses with JSON blocks
   - parse_text_find_number()        : Extract numeric answers from responses
   - create_logger()                 : Create unique loggers with file handlers
   - get_tasks()                     : Load video tasks from annotation files
   - parse_and_output_result()       : Generate experiment metrics and reports

8. utils/utils_clip.py - CLIP Embeddings and Frame Retrieval
-----------------------------------------------------------
   CLIPEmbeddingManager Class:
   - Manages CLIP embedding cache and retrieval operations
   - Handles embedding lookup for text descriptions
   
   Frame Retrieval Functions:
   - retrieve_frames_by_section()    : Sample frames from specified segments
   - _sample_frames_from_range()     : Even distribution within frame ranges
   
   Legacy Functions:
   - get_embeddings(), cache_clip (for backward compatibility)

9. main.py - Command Line Interface
-----------------------------------
   Purpose: Standardized CLI entry point with comprehensive argument parsing
   
   Execution Modes:
   - single:    Custom experiment with user-specified parameters
   - multiple:  Pre-configured multi-model comparison experiments
   - detailed:  Experiment using detailed caption generation
   
   Command Line Arguments:
   - Model Configuration: --viewer-model, --scheduler-model
   - Processing Options:  --max-videos, --max-rounds, --caption-function
   - Experiment Setup:    --experiment-name, --video-list
   - Performance:         --no-cache, --no-multiprocess
   - Debugging:          --llm-logging

10. parse_data.py - Data Management Utilities
---------------------------------------------
    VideoDataManager Class:
    - Validates video file accessibility and format
    - Converts JSON annotations to video ID lists
    - Checks video availability across directories
    
    OutputOrganizer Class:
    - Organizes experiment output directories
    - Moves video results into structured 'videos' subdirectories
    
    ResultProcessor Class:
    - Processes experiment results in batch
    - Generates summary reports across multiple experiments
    
    CLI Actions:
    - validate:  Video file validation and filtering
    - organize:  Output directory restructuring
    - process:   Batch result processing
    - summary:   Multi-experiment summary generation


WORKFLOW (Standardized Pipeline)
================================

High-Level Process:

1. **Initialization**
   â””â”€â”€ VideoAgent(viewer_model, scheduler_model, max_rounds, use_cache)
       â”œâ”€â”€ Initialize CaptionProcessor with viewer model and cache settings
       â”œâ”€â”€ Initialize QuestionProcessor with scheduler model
       â””â”€â”€ Set up logging and configuration

2. **Experiment Setup**
   â””â”€â”€ run_experiment(experiment_name, max_test_videos, video_list_file, ...)
       â”œâ”€â”€ Create structured output directory with model and parameter info
       â”œâ”€â”€ Setup global and LLM logging (if enabled)
       â”œâ”€â”€ Load video tasks from annotation file
       â””â”€â”€ Choose caption generation function (multi_level vs detailed)

3. **Video Processing Pipeline** (per video)
   â””â”€â”€ process_single_video(video_id, annotation, logs, output_dir, caption_function)
       â”œâ”€â”€ Load video frames with configurable interval
       â”œâ”€â”€ Create VideoMemory instance with frame data
       â”œâ”€â”€ Format question with multiple choice options
       â””â”€â”€ Execute iterative analysis pipeline

4. **Iterative Analysis Pipeline** (per round)
   â””â”€â”€ _run_analysis_pipeline(memory, formatted_question, question, logger, caption_function)
       â”œâ”€â”€ **Initial Sampling**: Evenly distribute DEFAULT_INITIAL_FRAMES
       â””â”€â”€ **Analysis Loop** (while confidence < 3 and rounds < MAX_ROUNDS):
           â”œâ”€â”€ **Caption Generation**:
           â”‚   â”œâ”€â”€ CaptionProcessor.generate_multi_level_captions() OR
           â”‚   â””â”€â”€ CaptionProcessor.generate_detailed_captions()
           â”œâ”€â”€ **Question Answering**:
           â”‚   â””â”€â”€ QuestionProcessor.answer_question()
           â”œâ”€â”€ **Confidence Evaluation**:
           â”‚   â””â”€â”€ QuestionProcessor.evaluate_confidence()
           â””â”€â”€ **Smart Resampling** (if confidence < 3):
               â””â”€â”€ QuestionProcessor.generate_segment_steps()

5. **Result Processing and Output**
   â””â”€â”€ After pipeline completion:
       â”œâ”€â”€ Calculate accuracy metrics (correct, frame count, etc.)
       â”œâ”€â”€ Save VideoMemory state and sampled frames
       â”œâ”€â”€ Export question, results, and logs
       â””â”€â”€ Generate experiment-wide accuracy statistics


DETAILED FUNCTION TREE (Standardized)
=====================================

VideoAgent.run_experiment()                    # Main experiment orchestrator
â”œâ”€â”€ VideoAgent._create_output_directory()      # Generate structured output paths
â”œâ”€â”€ VideoAgent._setup_logging()               # Configure experiment logging
â”œâ”€â”€ get_tasks()                               # Load video tasks from annotations
â”œâ”€â”€ VideoAgent._process_videos()              # Coordinate video processing
â”‚   â””â”€â”€ [PARALLEL/SEQUENTIAL EXECUTION]
â”‚       â””â”€â”€ VideoAgent.process_single_video() # Process individual video
â”‚           â”œâ”€â”€ get_video_frames()            # Extract frames using OpenCV
â”‚           â”œâ”€â”€ VideoMemory.__init__()        # Initialize video state management
â”‚           â””â”€â”€ VideoAgent._run_analysis_pipeline() # Execute iterative analysis
â”‚               â”œâ”€â”€ [INITIAL SAMPLING]        # Evenly distribute initial frames
â”‚               â””â”€â”€ [ANALYSIS LOOP] (max MAX_ROUNDS, confidence < 3)
â”‚                   â”œâ”€â”€ CaptionProcessor.generate_multi_level_captions()
â”‚                   â”‚   â”œâ”€â”€ CaptionProcessor.generate_detailed_captions()
â”‚                   â”‚   â”‚   â”œâ”€â”€ get_llm_response()     # LLM call with images
â”‚                   â”‚   â”‚   â””â”€â”€ CaptionProcessor._parse_and_store_captions()
â”‚                   â”‚   â””â”€â”€ CaptionProcessor._generate_event_descriptions()
â”‚                   â”‚       â”œâ”€â”€ get_llm_response()     # LLM call for events
â”‚                   â”‚       â””â”€â”€ CaptionProcessor._parse_and_store_events()
â”‚                   â”œâ”€â”€ QuestionProcessor.answer_question()
â”‚                   â”‚   â””â”€â”€ get_llm_response()         # LLM call for Q&A
â”‚                   â”œâ”€â”€ QuestionProcessor.evaluate_confidence()
â”‚                   â”‚   â””â”€â”€ get_llm_response()         # LLM call for confidence
â”‚                   â””â”€â”€ QuestionProcessor.generate_segment_steps()
â”‚                       â”œâ”€â”€ get_llm_response()         # LLM call for segments
â”‚                       â”œâ”€â”€ QuestionProcessor._process_segment_response()
â”‚                       â””â”€â”€ retrieve_frames_by_section() # Smart frame sampling
â”‚               â””â”€â”€ [POST-PROCESSING]
â”‚                   â”œâ”€â”€ VideoMemory.output()           # Export memory and frames
â”‚                   â”œâ”€â”€ Save formatted question
â”‚                   â””â”€â”€ Save video-specific results
â””â”€â”€ parse_and_output_result()                  # Generate experiment metrics


KEY IMPROVEMENTS IN STANDARDIZED VERSION
========================================

1. **Modular Architecture**: Clean separation of concerns with dedicated modules
2. **Configuration Management**: Centralized config.py for all parameters
3. **Error Handling**: Comprehensive exception handling and logging
4. **Documentation**: Extensive docstrings and type hints throughout
5. **Backward Compatibility**: Legacy function support for existing code
6. **Import Flexibility**: Supports both package and direct execution imports
7. **CLI Interface**: Comprehensive command-line argument parsing
8. **Testing Framework**: Import validation and module testing capabilities
9. **Data Management**: Standardized utilities for video and result processing
10. **Caching System**: Robust LLM response and embedding caching with error recovery 